{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store every image in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = (r'.\\fire_dataset')\n",
    "categories = ['non_fire_images', 'fire_images']\n",
    "for i in categories:\n",
    "    path = os.path.join(data_dir, i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Resize each image to same size for fast processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "image_array = cv2.resize(img_array, (img_size,img_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dno = cv2.imread('./fire_dataset/non_fire_images/non_fire.12.png')\n",
    "dyes = cv2.imread('./fire_dataset/fire_images/fire.2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert each image to grayscale and append into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "\n",
    "for i in categories:\n",
    "    train_path = os.path.join(data_dir,i)\n",
    "    tag = categories.index(i)\n",
    "    for img in os.listdir(train_path):\n",
    "        try:\n",
    "            image_arr = cv2.imread(os.path.join(train_path , img), cv2.IMREAD_GRAYSCALE)\n",
    "            new_image_array = cv2.resize(image_arr, (img_size,img_size))\n",
    "            train_data.append([new_image_array , tag])\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the features and target in to X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i,j in train_data:\n",
    "    X.append(i)\n",
    "    y.append(j)\n",
    "X = np.array(X).reshape(-1,img_size,img_size)\n",
    "print(X.shape)\n",
    "X = X/255.0  \n",
    "X = X.reshape(-1,128,128,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot encode the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "y_enc = to_categorical(y, num_classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(X , y_enc , test_size = 0.1, random_state = 42)\n",
    "X_train , X_val, y_train, y_val = train_test_split(X_train , y_train , test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sathvik Samineni\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (128,128,1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (2,2),padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 256, kernel_size = (2,2),padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4, activation = \"softmax\"))\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor='val_acc', \n",
    "    mode='max',\n",
    "    patience = 3\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "imggen = ImageDataGenerator(\n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False, \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        zca_whitening=False,  \n",
    "        rotation_range=0,\n",
    "        zoom_range = 0,\n",
    "        width_shift_range=0,  \n",
    "        height_shift_range=0,  \n",
    "        horizontal_flip=True,  \n",
    "        vertical_flip=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SATHVI~1\\AppData\\Local\\Temp/ipykernel_17956/19206160.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(imggen.flow(X_train,y_train,batch_size = batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA: 0s - loss: 0.6198 - accuracy: 0.7184WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50/50 [==============================] - 39s 759ms/step - loss: 0.6198 - accuracy: 0.7184 - val_loss: 0.4877 - val_accuracy: 0.7556\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4839 - accuracy: 0.7816WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 0.4839 - accuracy: 0.7816 - val_loss: 0.3842 - val_accuracy: 0.8778\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.4000 - accuracy: 0.8169WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 0.4000 - accuracy: 0.8169 - val_loss: 0.4626 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3777 - accuracy: 0.8270WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 0.3777 - accuracy: 0.8270 - val_loss: 0.3484 - val_accuracy: 0.8556\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.8636WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 0.3428 - accuracy: 0.8636 - val_loss: 0.3706 - val_accuracy: 0.8222\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3368 - accuracy: 0.8624WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 0.3368 - accuracy: 0.8624 - val_loss: 0.3446 - val_accuracy: 0.8667\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.8775WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 0.2945 - accuracy: 0.8775 - val_loss: 0.3479 - val_accuracy: 0.8444\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.3238 - accuracy: 0.8662WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 0.3238 - accuracy: 0.8662 - val_loss: 0.2841 - val_accuracy: 0.8889\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.8875WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 0.2867 - accuracy: 0.8875 - val_loss: 0.2795 - val_accuracy: 0.8889\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - ETA: 0s - loss: 0.2415 - accuracy: 0.9003WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "50/50 [==============================] - 38s 764ms/step - loss: 0.2415 - accuracy: 0.9003 - val_loss: 0.3000 - val_accuracy: 0.9222\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"models/model_weights.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "imggen.fit(X_train)\n",
    "history = model.fit_generator(imggen.flow(X_train,y_train,batch_size = batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,y_val),\n",
    "                              steps_per_epoch = X_train.shape[0] // batch_size,\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### serialize model structure to JSON\n",
    "model_json = model.to_json()\n",
    "with open(r\".\\models\\firenet_model.model\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'firenet_model.model',\n",
       " 'mask_detector.model',\n",
       " 'model_weights.h5']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(r\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
